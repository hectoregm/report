\chapter{Situación actual}

\section{Contexto}
De 2000 a 2002 se tuvo una crisis energética en el estado de California en los
Estados Unidos de América, esta crisis provocó que el gobierno del estado empezara a
tomar decisiones de largo plazo en su estrategia energética. En los años
subsecuentes se aprobaron nuevas leyes para incentivar el uso de energía renovable,
la producción de energía, etcétera.

Para el 2010 se aprobó una nueva legislación que permitía un nuevo esquema
de cobro a las empresas generadoras de electricidad. Este nuevo esquema
llamado \textit{hora de consumo} (\textit{time-of-use TOU}) define que las
tasas de cobro varíen en función de la temporada y la hora del día en que
se usa la energía eléctrica, en contraste con las tasas fijas tradicionales.

En un esquema \texttt{TOU} se definen tres tarifas y sus zonas de tiempo asociadas:

\begin{itemize}
\item  Demanda baja: es la tarifa mas baja, se aplica durante las horas de la
  mañana, en la noche y los fines de semana.
\item Demanda mediana: es la tarifa intermedia, se aplica durante las horas de
  10 am a 1pm y de 7 pm a 9 pm.
\item Demanda Alta: es la tarifa mas cara, se aplica durante las horas de
  1 pm a 7 pm.
\end{itemize}

El objetivo de un esquema \texttt{TOU} es el distribuir la carga de la red
eléctrica, alentando a los usuarios a cambiar su consumo durante periodos
de demanda alta a periodos de demanda baja, al bajar la demanda en los periodos
de demanda alta provoca que se reduzcan los costos de generación de energía de
forma general.

Un esquema \texttt{TOU} es solo posible con la llegada de los medidores
inteligentes, a diferencia de los antiguos medidores analógicos los medidores
inteligentes son capaces de medir el consumo de electricidad de forma instantánea,
de distinguir y facturar el consumo de electricidad según el momento en que se
esta realizando el consumo. Desde inicios del 2010 Pacific Gas and
Electric Company (PG\&E) empezó la instalación de medidores inteligentes
en su territorio, por lo que para inicios del 2012 ya casi había
completado la transición de los medidores.

Como fecha de arranque de la nueva legislación se puso el mes de noviembre del 2012,
las empresas como PG\&E podían iniciar la transición a un esquema \texttt{TOU}
de sus usuarios PyMES. Una parte vital para permitir esta transición es que
PG\&E brindara herramientas para que el usuario final pudiera analizar sus
gastos de energía y tomar decisiones sobre su consumo de energía según las
nuevas tarifas y su historial de consumo.

En esta situación es que nace el sistema \textit{Progressive
  Energy Audit Tool} \ (PEAT) para solventar la necesidad de información
del usuario final sobre sus gastos de energía en una forma detallada.
La licitación para la implementación del sistema \texttt{PEAT} fue puesta
a concurso por parte PG\&E siendo la compañía C3 Energy la ganadora de dicha
licitación  ya que contaba con la infraestructura necesaria para el
procesamiento de una gran cantidad de datos de consumo de energía,
tiene un sistema de monitoreo de consumo de energía enfocada a empresas de nivel
multinacional. El reto era pasar de un sistema y procesos diseñados
para una docena de clientes, a un sistema que diera servicio a
cientos de miles de clientes PyMES.

\section{Objetivo general}

El objetivo general del sistema \texttt{PEAT} es dar la mayor utilidad posible
a usuarios PyMES con la menor información disponible, fomentando en el usuario
el compartir más información sobre su empresa, obteniendo un mejor control
acerca de su consumo energético.

El sistema debe además permitir el ingreso progresivo de información, por medio
de una serie de preguntas especificas al usuario, dando mejores recomendaciones
para bajar su consumo energético conforme el sistema obtiene mas información.
A partir de la información obtenida el sistema debe permitir el monitoreo
y revisión del consumo energético de forma detallada, ya sea en horas,
días, meses y años.

\section{Objetivos secundarios}

Los objetivos secundarios que apoyan al objetivo general de este trabajo son:
\begin{itemize}
\item Implementación de una interfaz que permita la obtención
  de información del usuario de una forma eficaz y sencilla.
\item Dar información útil aunque el usuario solo proporcione el
  mínimo de información sobre su empresa.
\item Proporcionar recomendaciones para disminuir sus
  gastos en energía con base en el consumo e información proporcionada
  hasta el momento.
\item Autentificar a los usuarios mediante el uso de credenciales de acceso
  obtenidas en el portal web de PG\&E.
\item Diseñar e implementar una suite de pruebas unitarias, funcionales
  y de integración para los módulos críticos del sistema.
\item Soportar por lo menos a mil usuarios concurrentes.
\item Implementar la infraestructura para el despliegue continuo de la
  aplicación, permitiendo una retroalimentación continua sobre el
  funcionamiento del sistema.
\end{itemize}

\section{Arquitectura previa}
En C3 Energy ya se contaba con toda una infraestructura para el
procesamiento y análisis en tiempo real de datos de consumo eléctrico
y de gas.

El sistema consta de cuatro capas:

\begin{itemize}
\item Una capa de almacenamiento de información que era de referencia
  o datos ya procesados
\item Una capa de análisis en las que se hacia el análisis de los datos
  y que también tomaba el rol de capa de cache.
\item Una capa de servicios web que permitía acceder a los datos contenidos
  en las capas anteriores.
\item Una capa en donde están los sistemas que hacen uso de los
  servicios web para dar información al usuario final.
\end{itemize}

\subsection{Bases de datos}
Las dos primeras capas almacenan y analizan la información obtenida
de un gran numero de bases de datos externas relacionadas con temas
de energía. Todos estos datos son concentrados en una base de datos
central en la que se usaba Oracle Database 10g para este rol.

También se contaba con un cluster de Apache Cassandra el cual era usado
para realizar el análisis en tiempo real de los datos, además de servir
como capa de cache para los datos mas solicitados en el sistema.

\subsection{Servidor y API}
Sobre la anterior bases de datos se tenia un API que que permita el
hacer consultas y operaciones sobre los datos contenidos y/o analizados
en este sistema. Este API estaba implementado en Javascript bajo Rhino
que corre bajo la maquina virtual de Java (JVM), esto daba la ventaja
que se podía realizar la implementación de rutinas criticas en un
lenguaje con mejor rendimiento como Java. De esta forma se tenia que el
núcleo del servidor estaba implementado en Java con el resto del API
implementado en Javascript.

\subsection{Sistemas en producción}
Los sistemas ya existentes para varias empresas multinacionales
eran del tipo \textit{SPA (Single Page Application)} que son sistemas web
que tienen el fin de dar una experiencia de usuario similar a la
de una aplicación de escritorio.

Estos sistemas eran implementados usando un marco de trabajo hecho dentro
de la compañía usando Javascript. Se tenia una gran jerarquía de clases
que era compartida tanto para el servidor como con el cliente,
así se tenia que había una sola fuente de la descripción
de las clases y objetos del sistema.

Se hacia un uso extenso de la biblioteca Ext JS que es un marco de trabajo
en Javascript para construir sistemas \textit{SPA}, se hacia un uso particular
a su facultad para rápidamente generar todo tipo de gráficas para mostrar
información al usuario.

Entonces tenemos que tanto en el \textit{frontend} como en el \textit{backend}
se hacia uso de Javascript principalmente con un núcleo de Java para las partes
que requerían un rendimiento óptimo. Esto tenia varias ventajas:

\begin{itemize}
\item Reducir al mínimo el cambio de contexto entre lenguajes entre
  el frontend y el backend.
\item Reducir sustancialmente la cantidad de código redundante al no
  tenerse que reimplementar la jerarquía de objetos, que era pasada
  por el servidor en forma serializada por JSON y deserializada por el
  cliente
\item Había una única representación de una clase por ejemplo la
  clase \textit{Building} era una clase de Javascript que se usaba para
  tanto en el servidor como en el cliente.
\end{itemize}

\section{Propuesta de desarrollo}
En primera instancia se pensaba realizar el mismo tipo de sistema
a los que se venían desarrollando para cubrir los requerimientos
de \texttt{PEAT}, es decir realizar un cliente
de Javascript que hiciera uso del API y jerarquía de objetos ya
existente (con ciertas adicciones y modificaciones). Pero en los
primeros prototipos se lograron visualizar varios problemas con
este acercamiento:

\begin{itemize}
\item El tiempo para realizar la precarga de todos los módulos y
  objetos dados por el API en el cliente tomaba un tiempo
  considerable (5+ segs.). Los sistema anteriores eran usados
  por un numero reducido de personas autorizadas, que hacían uso
  extensivo del sistema en sesiones de larga duración, por lo
  que este tiempo de arranque era tolerable.
\item El tipo de interfases y experiencia de usuario que se obtenía
  usando Ext JS eran excelentes para el contexto de mostrar una gran
  cantidad de información al usuario, en \texttt{PEAT} el volumen
  era menor y la importancia era de que la experiencia de usuario
  fuera lo mas fluida y rápida posible.
\end{itemize}

Entonces se vio el de usar otro tipo de herramientas para construir
aplicaciones finales al usuario pero que permitieran rehusar todo el API
y jerarquía de objetos implementados hasta ese momento.

Después de varios prototipos con varios stacks de tecnología se decido
usar Ruby y el marco de trabajo Ruby on Rails.

Las razones principales fueron:
\begin{itemize}
\item Ruby tiene un gran soporte para la metaprogramación, es decir para la cremación
  de clases y sus atributos ``al vuelo''. Esto sera de vital importancia para lograr
  una buena integración con la jerarquía de clases ya definida en el \textit{backend}.
\item Ruby tiene una gran capacidad para implementar Domain Specific Languages (DSL)
  que permiten realizar lenguajes específicos al problema que se esta resolviendo.
  Característica que sera usada para lograr la integración con el
  \texttt{backend} y la automatización del despliegue de la aplicación.
\item Gran integración con una gran cantidad de utilerías y bibliotecas para
  desarrollar, diseñar y implementar interfases de usuario.
\item Gran soporte para realizar extensas pruebas unitarias, funcionales
  y de integración, por medio de librerías como rspec, cucumber, capybara, etc.
\end{itemize}

En el proyecto de implementación del sistema \texttt{PEAT}
se tienen tres partes principales de desarrollo:
(a) el \textit{backend}  implementado en su mayoría usando
Javascript, con un núcleo escrito en Java, (b) una biblioteca en Ruby que permite
la interacción del \textit{backend} son el servidor de \texttt{PEAT} y
(c) el \textit{frontend} escrito también con Ruby haciendo uso del
marco de trabajo Ruby on Rails.

El \textit{frontend} seria implementado por medio del marco de trabajo Ruby on Rails,
haciendo uso de alguna biblioteca para dar estructura a los módulos de Javascript
que se usaran en la vista. Para las gráficas y manejo de datos se seguiría
haciendo uso de Ext JS por su gran facilidad para implementar cualquier tipo
de gráfica.

El servidor de \texttt{PEAT} tendría el rol de recibir las peticiones de la
interfaz web y coordinar las peticiones necesarias al \textit{backend}. El trabajo de
la realización de las peticiones a los servicios web ya existentes y la creación
de clases y objetos en Ruby basados en la jerarquía de clases definida en Javascript
seria realizado por la biblioteca \texttt{Bezel}, la cual seria implementada
desde cero.

Aunque en la parte del \texttt{backend} se tenia un sistema de procesamiento
y análisis de datos ya en producción era necesario el diseño e implementación
de dos nuevos componentes en el \texttt{backend}. El primero era el modulo de
recomendaciones (\textit{Recommendations API}) el cual según las respuestas
dadas del usuario debía poder generar recomendaciones hechas a la medida al
contexto de operación de cada usuario. El segundo modulo era el modulo de
desagregación (\textit{Disaggregation API}) que tomaba los datos de consumo
del usuario y usando aprendizaje de maquina separaba este consumo en sus
diferentes partes.

Para acelerar el desarrollo del sistema se propuso que se hiciera la implementación
del frontend y del backend en forma concurrente, dado que una parte significativa
estaría en desarrollo se haría uso de datos estáticos contenidos en una base de
datos como PostgreSQL mientras se esperaba en la implementación de los nuevos
componentes del backend y de la implementación de la librería \texttt{Bezel}.

Dado que al principio el frontend haría uso de un backend provisional con datos
estáticos al hacer el cambio al backend final se tendrían varias incompatibilidades
para acelerar este proceso de integración se propuso el uso de una suite de
pruebas de integración principalmente para asegurar que la transición fuera exitosa
y con la menor cantidad de bugs.

\jcimage{1.0}{imagenes/PEAT-Architecture.png}{Esquema de alto nivel de la arquitectura para \texttt{PEAT}}
